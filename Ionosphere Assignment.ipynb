{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, optimizers, regularizers, models\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.0</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.891738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.601068</td>\n",
       "      <td>0.115889</td>\n",
       "      <td>0.550095</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396135</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>-0.069538</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>-0.027907</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.349364</td>\n",
       "      <td>0.014480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.311155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>0.441435</td>\n",
       "      <td>0.519862</td>\n",
       "      <td>0.460810</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>0.483851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578451</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>0.516205</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>0.575886</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>0.571483</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>0.522663</td>\n",
       "      <td>0.468337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472135</td>\n",
       "      <td>-0.064735</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.087110</td>\n",
       "      <td>-0.048075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.332390</td>\n",
       "      <td>0.286435</td>\n",
       "      <td>-0.443165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.236885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.242595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.165350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871110</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.728730</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.684210</td>\n",
       "      <td>0.018290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553890</td>\n",
       "      <td>-0.015050</td>\n",
       "      <td>0.708240</td>\n",
       "      <td>-0.017690</td>\n",
       "      <td>0.496640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409560</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>0.200120</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>0.171660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature1  feature2    feature3    feature4    feature5    feature6  \\\n",
       "count  351.000000     351.0  351.000000  351.000000  351.000000  351.000000   \n",
       "mean     0.891738       0.0    0.641342    0.044372    0.601068    0.115889   \n",
       "std      0.311155       0.0    0.497708    0.441435    0.519862    0.460810   \n",
       "min      0.000000       0.0   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      1.000000       0.0    0.472135   -0.064735    0.412660   -0.024795   \n",
       "50%      1.000000       0.0    0.871110    0.016310    0.809200    0.022800   \n",
       "75%      1.000000       0.0    1.000000    0.194185    1.000000    0.334655   \n",
       "max      1.000000       0.0    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         feature7    feature8    feature9   feature10  ...   feature25  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  ...  351.000000   \n",
       "mean     0.550095    0.119360    0.511848    0.181345  ...    0.396135   \n",
       "std      0.492654    0.520750    0.507066    0.483851  ...    0.578451   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000  ...   -1.000000   \n",
       "25%      0.211310   -0.054840    0.087110   -0.048075  ...    0.000000   \n",
       "50%      0.728730    0.014710    0.684210    0.018290  ...    0.553890   \n",
       "75%      0.969240    0.445675    0.953240    0.534195  ...    0.905240   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "        feature26   feature27   feature28   feature29   feature30   feature31  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean    -0.071187    0.541641   -0.069538    0.378445   -0.027907    0.352514   \n",
       "std      0.508495    0.516205    0.550025    0.575886    0.507974    0.571483   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%     -0.332390    0.286435   -0.443165    0.000000   -0.236885    0.000000   \n",
       "50%     -0.015050    0.708240   -0.017690    0.496640    0.000000    0.442770   \n",
       "75%      0.156765    0.999945    0.153535    0.883465    0.154075    0.857620   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "        feature32   feature33   feature34  \n",
       "count  351.000000  351.000000  351.000000  \n",
       "mean    -0.003794    0.349364    0.014480  \n",
       "std      0.513574    0.522663    0.468337  \n",
       "min     -1.000000   -1.000000   -1.000000  \n",
       "25%     -0.242595    0.000000   -0.165350  \n",
       "50%      0.000000    0.409560    0.000000  \n",
       "75%      0.200120    0.813765    0.171660  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ionosphere_data.csv', delimiter=',')\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1\n",
      "2\n",
      "feature2\n",
      "1\n",
      "feature3\n",
      "219\n",
      "feature4\n",
      "269\n",
      "feature5\n",
      "204\n",
      "feature6\n",
      "259\n",
      "feature7\n",
      "231\n",
      "feature8\n",
      "260\n",
      "feature9\n",
      "244\n",
      "feature10\n",
      "267\n",
      "feature11\n",
      "246\n",
      "feature12\n",
      "269\n",
      "feature13\n",
      "238\n",
      "feature14\n",
      "266\n",
      "feature15\n",
      "234\n",
      "feature16\n",
      "270\n",
      "feature17\n",
      "254\n",
      "feature18\n",
      "280\n",
      "feature19\n",
      "254\n",
      "feature20\n",
      "266\n",
      "feature21\n",
      "248\n",
      "feature22\n",
      "265\n",
      "feature23\n",
      "248\n",
      "feature24\n",
      "264\n",
      "feature25\n",
      "256\n",
      "feature26\n",
      "273\n",
      "feature27\n",
      "256\n",
      "feature28\n",
      "281\n",
      "feature29\n",
      "244\n",
      "feature30\n",
      "266\n",
      "feature31\n",
      "243\n",
      "feature32\n",
      "263\n",
      "feature33\n",
      "245\n",
      "feature34\n",
      "263\n",
      "label\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for feature in data:\n",
    "    print(feature)\n",
    "    print(len(data[feature].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1 2\n",
      "feature2 1\n",
      "feature3 219\n",
      "feature4 269\n",
      "feature5 204\n",
      "feature6 259\n",
      "feature7 231\n",
      "feature8 260\n",
      "feature9 244\n",
      "feature10 267\n",
      "feature11 246\n",
      "feature12 269\n",
      "feature13 238\n",
      "feature14 266\n",
      "feature15 234\n",
      "feature16 270\n",
      "feature17 254\n",
      "feature18 280\n",
      "feature19 254\n",
      "feature20 266\n",
      "feature21 248\n",
      "feature22 265\n",
      "feature23 248\n",
      "feature24 264\n",
      "feature25 256\n",
      "feature26 273\n",
      "feature27 256\n",
      "feature28 281\n",
      "feature29 244\n",
      "feature30 266\n",
      "feature31 243\n",
      "feature32 263\n",
      "feature33 245\n",
      "feature34 263\n",
      "label 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for feature in data:\n",
    "    print(feature , len(data[feature].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.891738</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.601068</td>\n",
       "      <td>0.115889</td>\n",
       "      <td>0.550095</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>0.476183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396135</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>-0.069538</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>-0.027907</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.349364</td>\n",
       "      <td>0.014480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.311155</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>0.441435</td>\n",
       "      <td>0.519862</td>\n",
       "      <td>0.460810</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>0.483851</td>\n",
       "      <td>0.563496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578451</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>0.516205</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>0.575886</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>0.571483</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>0.522663</td>\n",
       "      <td>0.468337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.472135</td>\n",
       "      <td>-0.064735</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.087110</td>\n",
       "      <td>-0.048075</td>\n",
       "      <td>0.021120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.332390</td>\n",
       "      <td>0.286435</td>\n",
       "      <td>-0.443165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.236885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.242595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.165350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871110</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.728730</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.684210</td>\n",
       "      <td>0.018290</td>\n",
       "      <td>0.667980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553890</td>\n",
       "      <td>-0.015050</td>\n",
       "      <td>0.708240</td>\n",
       "      <td>-0.017690</td>\n",
       "      <td>0.496640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409560</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>0.200120</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>0.171660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature1    feature3    feature4    feature5    feature6    feature7  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean     0.891738    0.641342    0.044372    0.601068    0.115889    0.550095   \n",
       "std      0.311155    0.497708    0.441435    0.519862    0.460810    0.492654   \n",
       "min      0.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      1.000000    0.472135   -0.064735    0.412660   -0.024795    0.211310   \n",
       "50%      1.000000    0.871110    0.016310    0.809200    0.022800    0.728730   \n",
       "75%      1.000000    1.000000    0.194185    1.000000    0.334655    0.969240   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         feature8    feature9   feature10   feature11  ...   feature25  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  ...  351.000000   \n",
       "mean     0.119360    0.511848    0.181345    0.476183  ...    0.396135   \n",
       "std      0.520750    0.507066    0.483851    0.563496  ...    0.578451   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000  ...   -1.000000   \n",
       "25%     -0.054840    0.087110   -0.048075    0.021120  ...    0.000000   \n",
       "50%      0.014710    0.684210    0.018290    0.667980  ...    0.553890   \n",
       "75%      0.445675    0.953240    0.534195    0.957895  ...    0.905240   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "        feature26   feature27   feature28   feature29   feature30   feature31  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean    -0.071187    0.541641   -0.069538    0.378445   -0.027907    0.352514   \n",
       "std      0.508495    0.516205    0.550025    0.575886    0.507974    0.571483   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%     -0.332390    0.286435   -0.443165    0.000000   -0.236885    0.000000   \n",
       "50%     -0.015050    0.708240   -0.017690    0.496640    0.000000    0.442770   \n",
       "75%      0.156765    0.999945    0.153535    0.883465    0.154075    0.857620   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "        feature32   feature33   feature34  \n",
       "count  351.000000  351.000000  351.000000  \n",
       "mean    -0.003794    0.349364    0.014480  \n",
       "std      0.513574    0.522663    0.468337  \n",
       "min     -1.000000   -1.000000   -1.000000  \n",
       "25%     -0.242595    0.000000   -0.165350  \n",
       "50%      0.000000    0.409560    0.000000  \n",
       "75%      0.200120    0.813765    0.171660  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(data.columns[1], inplace=True, axis=1)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>0.50874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>0.73082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>0.52798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature3  feature4  feature5  feature6  feature7  feature8  \\\n",
       "0         1   0.99539  -0.05889   0.85243   0.02306   0.83398  -0.37708   \n",
       "1         1   1.00000  -0.18829   0.93035  -0.36156  -0.10868  -0.93597   \n",
       "2         1   1.00000  -0.03365   1.00000   0.00485   1.00000  -0.12062   \n",
       "3         1   1.00000  -0.45161   1.00000   1.00000   0.71216  -1.00000   \n",
       "4         1   1.00000  -0.02401   0.94140   0.06531   0.92106  -0.23255   \n",
       "\n",
       "   feature9  feature10  feature11  ...  feature26  feature27  feature28  \\\n",
       "0   1.00000    0.03760    0.85243  ...   -0.51171    0.41078   -0.46168   \n",
       "1   1.00000   -0.04549    0.50874  ...   -0.26569   -0.20468   -0.18401   \n",
       "2   0.88965    0.01198    0.73082  ...   -0.40220    0.58984   -0.22145   \n",
       "3   0.00000    0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4   0.77152   -0.16399    0.52798  ...   -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1     0\n",
       "feature3     0\n",
       "feature4     0\n",
       "feature5     0\n",
       "feature6     0\n",
       "feature7     0\n",
       "feature8     0\n",
       "feature9     0\n",
       "feature10    0\n",
       "feature11    0\n",
       "feature12    0\n",
       "feature13    0\n",
       "feature14    0\n",
       "feature15    0\n",
       "feature16    0\n",
       "feature17    0\n",
       "feature18    0\n",
       "feature19    0\n",
       "feature20    0\n",
       "feature21    0\n",
       "feature22    0\n",
       "feature23    0\n",
       "feature24    0\n",
       "feature25    0\n",
       "feature26    0\n",
       "feature27    0\n",
       "feature28    0\n",
       "feature29    0\n",
       "feature30    0\n",
       "feature31    0\n",
       "feature32    0\n",
       "feature33    0\n",
       "feature34    0\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     351\n",
       "unique      2\n",
       "top         g\n",
       "freq      225\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    351.000000\n",
       "mean       0.641026\n",
       "std        0.480384\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'] = [1 if lbl == 'g' else 0 for lbl in data['label']]\n",
    "data['label'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.909953</td>\n",
       "      <td>0.623455</td>\n",
       "      <td>0.016972</td>\n",
       "      <td>0.606826</td>\n",
       "      <td>0.104084</td>\n",
       "      <td>0.543575</td>\n",
       "      <td>0.077236</td>\n",
       "      <td>0.493908</td>\n",
       "      <td>0.211882</td>\n",
       "      <td>0.464048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411620</td>\n",
       "      <td>-0.054750</td>\n",
       "      <td>0.536748</td>\n",
       "      <td>-0.067042</td>\n",
       "      <td>0.401652</td>\n",
       "      <td>-0.035944</td>\n",
       "      <td>0.377411</td>\n",
       "      <td>-0.021653</td>\n",
       "      <td>0.359339</td>\n",
       "      <td>-0.016908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.286930</td>\n",
       "      <td>0.532433</td>\n",
       "      <td>0.452559</td>\n",
       "      <td>0.515302</td>\n",
       "      <td>0.463105</td>\n",
       "      <td>0.494804</td>\n",
       "      <td>0.530510</td>\n",
       "      <td>0.519804</td>\n",
       "      <td>0.470419</td>\n",
       "      <td>0.568089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577991</td>\n",
       "      <td>0.512303</td>\n",
       "      <td>0.524863</td>\n",
       "      <td>0.534410</td>\n",
       "      <td>0.568283</td>\n",
       "      <td>0.504333</td>\n",
       "      <td>0.546140</td>\n",
       "      <td>0.511561</td>\n",
       "      <td>0.511753</td>\n",
       "      <td>0.476106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.440970</td>\n",
       "      <td>-0.080395</td>\n",
       "      <td>0.437805</td>\n",
       "      <td>-0.041115</td>\n",
       "      <td>0.193600</td>\n",
       "      <td>-0.083610</td>\n",
       "      <td>0.083125</td>\n",
       "      <td>-0.050320</td>\n",
       "      <td>0.013730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004030</td>\n",
       "      <td>-0.297910</td>\n",
       "      <td>0.318695</td>\n",
       "      <td>-0.373510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.237960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.258435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.241075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.868890</td>\n",
       "      <td>0.008920</td>\n",
       "      <td>0.808040</td>\n",
       "      <td>0.013480</td>\n",
       "      <td>0.710630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.667250</td>\n",
       "      <td>0.033730</td>\n",
       "      <td>0.651640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556770</td>\n",
       "      <td>-0.033900</td>\n",
       "      <td>0.698110</td>\n",
       "      <td>-0.032800</td>\n",
       "      <td>0.524140</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>0.451140</td>\n",
       "      <td>-0.000150</td>\n",
       "      <td>0.421520</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.337165</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>0.365770</td>\n",
       "      <td>0.952005</td>\n",
       "      <td>0.624475</td>\n",
       "      <td>0.953755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918365</td>\n",
       "      <td>0.161605</td>\n",
       "      <td>0.999155</td>\n",
       "      <td>0.147625</td>\n",
       "      <td>0.916120</td>\n",
       "      <td>0.114080</td>\n",
       "      <td>0.868140</td>\n",
       "      <td>0.182150</td>\n",
       "      <td>0.832195</td>\n",
       "      <td>0.129765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature1    feature3    feature4    feature5    feature6    feature7  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000  211.000000  211.000000   \n",
       "mean     0.909953    0.623455    0.016972    0.606826    0.104084    0.543575   \n",
       "std      0.286930    0.532433    0.452559    0.515302    0.463105    0.494804   \n",
       "min      0.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      1.000000    0.440970   -0.080395    0.437805   -0.041115    0.193600   \n",
       "50%      1.000000    0.868890    0.008920    0.808040    0.013480    0.710630   \n",
       "75%      1.000000    1.000000    0.166370    1.000000    0.337165    0.969240   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         feature8    feature9   feature10   feature11  ...   feature25  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000  ...  211.000000   \n",
       "mean     0.077236    0.493908    0.211882    0.464048  ...    0.411620   \n",
       "std      0.530510    0.519804    0.470419    0.568089  ...    0.577991   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000  ...   -1.000000   \n",
       "25%     -0.083610    0.083125   -0.050320    0.013730  ...    0.004030   \n",
       "50%      0.000000    0.667250    0.033730    0.651640  ...    0.556770   \n",
       "75%      0.365770    0.952005    0.624475    0.953755  ...    0.918365   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "        feature26   feature27   feature28   feature29   feature30   feature31  \\\n",
       "count  211.000000  211.000000  211.000000  211.000000  211.000000  211.000000   \n",
       "mean    -0.054750    0.536748   -0.067042    0.401652   -0.035944    0.377411   \n",
       "std      0.512303    0.524863    0.534410    0.568283    0.504333    0.546140   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%     -0.297910    0.318695   -0.373510    0.000000   -0.237960    0.000000   \n",
       "50%     -0.033900    0.698110   -0.032800    0.524140   -0.000240    0.451140   \n",
       "75%      0.161605    0.999155    0.147625    0.916120    0.114080    0.868140   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "        feature32   feature33   feature34  \n",
       "count  211.000000  211.000000  211.000000  \n",
       "mean    -0.021653    0.359339   -0.016908  \n",
       "std      0.511561    0.511753    0.476106  \n",
       "min     -1.000000   -1.000000   -1.000000  \n",
       "25%     -0.258435    0.000000   -0.241075  \n",
       "50%     -0.000150    0.421520    0.000000  \n",
       "75%      0.182150    0.832195    0.129765  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = data.sample(frac= 0.6, random_state=125)\n",
    "testing_data = data.drop(training_data.index)\n",
    "training_label = training_data.iloc[:,-1]\n",
    "training_data = training_data.iloc[:,0:-1]\n",
    "testing_label = testing_data.iloc[:,-1]\n",
    "testing_data = testing_data.iloc[:,0:-1]\n",
    "\n",
    "training_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.864286</td>\n",
       "      <td>0.668300</td>\n",
       "      <td>0.085667</td>\n",
       "      <td>0.592390</td>\n",
       "      <td>0.133681</td>\n",
       "      <td>0.559922</td>\n",
       "      <td>0.182848</td>\n",
       "      <td>0.538886</td>\n",
       "      <td>0.135322</td>\n",
       "      <td>0.494472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372796</td>\n",
       "      <td>-0.095959</td>\n",
       "      <td>0.549015</td>\n",
       "      <td>-0.073299</td>\n",
       "      <td>0.343469</td>\n",
       "      <td>-0.015795</td>\n",
       "      <td>0.314990</td>\n",
       "      <td>0.023123</td>\n",
       "      <td>0.334329</td>\n",
       "      <td>0.061786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.343715</td>\n",
       "      <td>0.440720</td>\n",
       "      <td>0.422356</td>\n",
       "      <td>0.528398</td>\n",
       "      <td>0.458411</td>\n",
       "      <td>0.491003</td>\n",
       "      <td>0.500877</td>\n",
       "      <td>0.487830</td>\n",
       "      <td>0.501609</td>\n",
       "      <td>0.558032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580434</td>\n",
       "      <td>0.503512</td>\n",
       "      <td>0.504653</td>\n",
       "      <td>0.574686</td>\n",
       "      <td>0.587471</td>\n",
       "      <td>0.514992</td>\n",
       "      <td>0.607763</td>\n",
       "      <td>0.517263</td>\n",
       "      <td>0.540198</td>\n",
       "      <td>0.453964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.506990</td>\n",
       "      <td>-0.029003</td>\n",
       "      <td>0.377720</td>\n",
       "      <td>-0.000358</td>\n",
       "      <td>0.254958</td>\n",
       "      <td>-0.013057</td>\n",
       "      <td>0.118900</td>\n",
       "      <td>-0.045515</td>\n",
       "      <td>0.046063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.358925</td>\n",
       "      <td>0.279872</td>\n",
       "      <td>-0.513535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.218622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.222070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.085115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.874415</td>\n",
       "      <td>0.031315</td>\n",
       "      <td>0.818205</td>\n",
       "      <td>0.030495</td>\n",
       "      <td>0.773155</td>\n",
       "      <td>0.039345</td>\n",
       "      <td>0.737545</td>\n",
       "      <td>0.010235</td>\n",
       "      <td>0.688590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521495</td>\n",
       "      <td>-0.004775</td>\n",
       "      <td>0.737180</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.472820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.407060</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.240998</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.320568</td>\n",
       "      <td>0.968840</td>\n",
       "      <td>0.498565</td>\n",
       "      <td>0.952295</td>\n",
       "      <td>0.354205</td>\n",
       "      <td>0.961462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.859710</td>\n",
       "      <td>0.144205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.159832</td>\n",
       "      <td>0.858873</td>\n",
       "      <td>0.185885</td>\n",
       "      <td>0.846942</td>\n",
       "      <td>0.207022</td>\n",
       "      <td>0.790303</td>\n",
       "      <td>0.236250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature1    feature3    feature4    feature5    feature6    feature7  \\\n",
       "count  140.000000  140.000000  140.000000  140.000000  140.000000  140.000000   \n",
       "mean     0.864286    0.668300    0.085667    0.592390    0.133681    0.559922   \n",
       "std      0.343715    0.440720    0.422356    0.528398    0.458411    0.491003   \n",
       "min      0.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      1.000000    0.506990   -0.029003    0.377720   -0.000358    0.254958   \n",
       "50%      1.000000    0.874415    0.031315    0.818205    0.030495    0.773155   \n",
       "75%      1.000000    1.000000    0.240998    1.000000    0.320568    0.968840   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         feature8    feature9   feature10   feature11  ...   feature25  \\\n",
       "count  140.000000  140.000000  140.000000  140.000000  ...  140.000000   \n",
       "mean     0.182848    0.538886    0.135322    0.494472  ...    0.372796   \n",
       "std      0.500877    0.487830    0.501609    0.558032  ...    0.580434   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000  ...   -1.000000   \n",
       "25%     -0.013057    0.118900   -0.045515    0.046063  ...    0.000000   \n",
       "50%      0.039345    0.737545    0.010235    0.688590  ...    0.521495   \n",
       "75%      0.498565    0.952295    0.354205    0.961462  ...    0.859710   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "        feature26   feature27   feature28   feature29   feature30   feature31  \\\n",
       "count  140.000000  140.000000  140.000000  140.000000  140.000000  140.000000   \n",
       "mean    -0.095959    0.549015   -0.073299    0.343469   -0.015795    0.314990   \n",
       "std      0.503512    0.504653    0.574686    0.587471    0.514992    0.607763   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%     -0.358925    0.279872   -0.513535    0.000000   -0.218622    0.000000   \n",
       "50%     -0.004775    0.737180    0.000200    0.472820    0.000000    0.433105   \n",
       "75%      0.144205    1.000000    0.159832    0.858873    0.185885    0.846942   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "        feature32   feature33   feature34  \n",
       "count  140.000000  140.000000  140.000000  \n",
       "mean     0.023123    0.334329    0.061786  \n",
       "std      0.517263    0.540198    0.453964  \n",
       "min     -1.000000   -1.000000   -1.000000  \n",
       "25%     -0.222070    0.000000   -0.085115  \n",
       "50%      0.000000    0.407060    0.000000  \n",
       "75%      0.207022    0.790303    0.236250  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1     0\n",
       "feature3     0\n",
       "feature4     0\n",
       "feature5     0\n",
       "feature6     0\n",
       "feature7     0\n",
       "feature8     0\n",
       "feature9     0\n",
       "feature10    0\n",
       "feature11    0\n",
       "feature12    0\n",
       "feature13    0\n",
       "feature14    0\n",
       "feature15    0\n",
       "feature16    0\n",
       "feature17    0\n",
       "feature18    0\n",
       "feature19    0\n",
       "feature20    0\n",
       "feature21    0\n",
       "feature22    0\n",
       "feature23    0\n",
       "feature24    0\n",
       "feature25    0\n",
       "feature26    0\n",
       "feature27    0\n",
       "feature28    0\n",
       "feature29    0\n",
       "feature30    0\n",
       "feature31    0\n",
       "feature32    0\n",
       "feature33    0\n",
       "feature34    0\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data.to_numpy()\n",
    "training_label = training_label.to_numpy().astype('float32')\n",
    "testing_data = testing_data.to_numpy()\n",
    "testing_label = testing_label.to_numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                2176      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 6,401\n",
      "Trainable params: 6,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(training_data.shape[1],)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,  activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 2s 125ms/step - loss: 0.5996 - accuracy: 0.6753 - val_loss: 0.4853 - val_accuracy: 0.8372\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4938 - accuracy: 0.7686 - val_loss: 0.4234 - val_accuracy: 0.8837\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4670 - accuracy: 0.8154 - val_loss: 0.3824 - val_accuracy: 0.8837\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3642 - accuracy: 0.8960 - val_loss: 0.3431 - val_accuracy: 0.9070\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.3826 - accuracy: 0.8547 - val_loss: 0.3070 - val_accuracy: 0.9535\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.3235 - accuracy: 0.8945 - val_loss: 0.2816 - val_accuracy: 0.9767\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2929 - accuracy: 0.9257 - val_loss: 0.2520 - val_accuracy: 0.9767\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.2515 - accuracy: 0.9477 - val_loss: 0.2358 - val_accuracy: 0.9767\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.2570 - accuracy: 0.9219 - val_loss: 0.2168 - val_accuracy: 0.9767\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.2528 - accuracy: 0.9383 - val_loss: 0.2023 - val_accuracy: 0.9767\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.2547 - accuracy: 0.8915 - val_loss: 0.1978 - val_accuracy: 0.9767\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2131 - accuracy: 0.9244 - val_loss: 0.1856 - val_accuracy: 0.9767\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.1812 - accuracy: 0.9320 - val_loss: 0.1798 - val_accuracy: 0.9767\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.1466 - accuracy: 0.9660 - val_loss: 0.1729 - val_accuracy: 0.9767\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.1580 - accuracy: 0.9576 - val_loss: 0.1645 - val_accuracy: 0.9767\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.1925 - accuracy: 0.9365 - val_loss: 0.1570 - val_accuracy: 0.9767\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.1372 - accuracy: 0.9549 - val_loss: 0.1489 - val_accuracy: 0.9767\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.1138 - accuracy: 0.9737 - val_loss: 0.1475 - val_accuracy: 0.9767\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.1533 - accuracy: 0.9493 - val_loss: 0.1462 - val_accuracy: 0.9767\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.1419 - accuracy: 0.9485 - val_loss: 0.1380 - val_accuracy: 0.9767\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.1334 - accuracy: 0.9617 - val_loss: 0.1355 - val_accuracy: 0.9767\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.1219 - accuracy: 0.9532 - val_loss: 0.1368 - val_accuracy: 0.9767\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0820 - accuracy: 0.9828 - val_loss: 0.1340 - val_accuracy: 0.9767\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.1241 - accuracy: 0.9617 - val_loss: 0.1379 - val_accuracy: 0.9767\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0716 - accuracy: 0.9827 - val_loss: 0.1353 - val_accuracy: 0.9767\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0606 - accuracy: 0.9877 - val_loss: 0.1443 - val_accuracy: 0.9767\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0822 - accuracy: 0.9844 - val_loss: 0.1293 - val_accuracy: 0.9767\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0538 - accuracy: 0.9931 - val_loss: 0.1284 - val_accuracy: 0.9767\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0579 - accuracy: 0.9924 - val_loss: 0.1174 - val_accuracy: 0.9767\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0766 - accuracy: 0.9762 - val_loss: 0.1282 - val_accuracy: 0.9767\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0508 - accuracy: 0.9947 - val_loss: 0.1087 - val_accuracy: 0.9767\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0633 - accuracy: 0.9805 - val_loss: 0.1189 - val_accuracy: 0.9767\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0638 - accuracy: 0.9763 - val_loss: 0.1181 - val_accuracy: 0.9767\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.1319 - accuracy: 0.9600 - val_loss: 0.1141 - val_accuracy: 0.9767\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0349 - accuracy: 0.9936 - val_loss: 0.1090 - val_accuracy: 0.9767\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0499 - accuracy: 0.9717 - val_loss: 0.1261 - val_accuracy: 0.9767\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0475 - accuracy: 0.9965 - val_loss: 0.1244 - val_accuracy: 0.9767\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0369 - accuracy: 0.9872 - val_loss: 0.1132 - val_accuracy: 0.9767\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0672 - accuracy: 0.9835 - val_loss: 0.1091 - val_accuracy: 0.9767\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0459 - accuracy: 0.9902 - val_loss: 0.1112 - val_accuracy: 0.9767\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0430 - accuracy: 0.9836 - val_loss: 0.1131 - val_accuracy: 0.9767\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0212 - accuracy: 0.9918 - val_loss: 0.1245 - val_accuracy: 0.9767\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0761 - accuracy: 0.9743 - val_loss: 0.0870 - val_accuracy: 0.9767\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0276 - accuracy: 0.9965 - val_loss: 0.0899 - val_accuracy: 0.9767\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0441 - accuracy: 0.9869 - val_loss: 0.0832 - val_accuracy: 0.9767\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0445 - accuracy: 0.9902 - val_loss: 0.0830 - val_accuracy: 0.9767\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0308 - accuracy: 0.9965 - val_loss: 0.0945 - val_accuracy: 0.9767\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0473 - accuracy: 0.9784 - val_loss: 0.0949 - val_accuracy: 0.9767\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0322 - accuracy: 0.9890 - val_loss: 0.1221 - val_accuracy: 0.9767\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.1101 - val_accuracy: 0.9767\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0414 - accuracy: 0.9849 - val_loss: 0.1007 - val_accuracy: 0.9767\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 0.9919 - val_loss: 0.0707 - val_accuracy: 0.9767\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0149 - accuracy: 0.9985 - val_loss: 0.0838 - val_accuracy: 0.9767\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0434 - accuracy: 0.9916 - val_loss: 0.0886 - val_accuracy: 0.9767\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0353 - accuracy: 0.9916 - val_loss: 0.0944 - val_accuracy: 0.9767\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0914 - val_accuracy: 0.9767\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0140 - accuracy: 0.9946 - val_loss: 0.1170 - val_accuracy: 0.9767\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.1225 - val_accuracy: 0.9767\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0170 - accuracy: 0.9926 - val_loss: 0.0957 - val_accuracy: 0.9767\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0137 - accuracy: 0.9973 - val_loss: 0.0918 - val_accuracy: 0.9767\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0218 - accuracy: 0.9936 - val_loss: 0.0668 - val_accuracy: 0.9767\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0263 - accuracy: 0.9838 - val_loss: 0.0675 - val_accuracy: 0.9767\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9767\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 0.1090 - val_accuracy: 0.9767\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 0.9767\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0334 - accuracy: 0.9838 - val_loss: 0.1006 - val_accuracy: 0.9767\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9767\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1147 - val_accuracy: 0.9767\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1088 - val_accuracy: 0.9767\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0187 - accuracy: 0.9901 - val_loss: 0.0743 - val_accuracy: 0.9767\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 0.9767\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 0.9767\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0292 - accuracy: 0.9892 - val_loss: 0.0705 - val_accuracy: 0.9767\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0115 - accuracy: 0.9946 - val_loss: 0.0638 - val_accuracy: 0.9767\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.0568 - val_accuracy: 0.9767\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0650 - val_accuracy: 0.9767\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 0.9767\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0284 - accuracy: 0.9838 - val_loss: 0.0776 - val_accuracy: 0.9767\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0069 - accuracy: 0.9965 - val_loss: 0.0807 - val_accuracy: 0.9767\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 0.0966 - val_accuracy: 0.9767\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9767\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9767\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0825 - val_accuracy: 0.9767\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0652 - val_accuracy: 0.9767\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0065 - accuracy: 0.9973 - val_loss: 0.0838 - val_accuracy: 0.9767\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0761 - accuracy: 0.9946 - val_loss: 0.0616 - val_accuracy: 0.9767\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0078 - accuracy: 0.9956 - val_loss: 0.0661 - val_accuracy: 0.9767\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0635 - val_accuracy: 0.9767\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0155 - accuracy: 0.9973 - val_loss: 0.0566 - val_accuracy: 0.9535\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9767\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0823 - val_accuracy: 0.9767\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.0609 - val_accuracy: 0.9767\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9767\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9767\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 0.9767\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9767\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 0.9767\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1132 - val_accuracy: 0.9767\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 0.9767\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0061 - accuracy: 0.9956 - val_loss: 0.0833 - val_accuracy: 0.9767\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'RMSprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(training_data, training_label, validation_split=0.2, epochs=100, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist_dict = history.history\n",
    "loss_values = hist_dict['loss']\n",
    "val_loss_values = hist_dict['val_loss']\n",
    "epochs = range(100)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_values = hist_dict['accuracy']\n",
    "val_acc_values = hist_dict['val_accuracy']\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.9357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40398627519607544, 0.9357143044471741]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation = model.evaluate(testing_data, testing_label)\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict=model.predict(testing_data)\n",
    "pred_y = (predict > 0.5)\n",
    "tf.math.confusion_matrix(\n",
    "    testing_label, pred_y, num_classes=2, weights=None, dtype=tf.dtypes.int32,\n",
    "    name=None\n",
    ")\n",
    "\n",
    "np.count_nonzero(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
